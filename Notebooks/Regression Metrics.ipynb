{
  "cells": [
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "# Mean Absolute Error\n\nThe Mean Absolute Error (or MAE) is the sum of the absolute differences between predictions and actual values. It gives an idea of how wrong the predictions were.\n\nThe measure gives an idea of the magnitude of the error, but no idea of the direction (e.g. over or under predicting).\n\nIt is defined as:\n\n$$\\frac{\\sum_{i = 1}^n\\mid y_i - x_i \\mid}{n}$$"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\ndef mean_absolute_error(y_pred, y_true):\n    \"\"\"Calculates the Mean Absolure error between the two input numpy arrays.\n    \n    Args:\n        rgs:\n        y_pred (numpy ndarray): The true lables. Ground truth.\n        y_true (numpy ndarray): The predicted lables. Predictions.\n    \n    Raises:\n        Assertion Exception: If yTrue or yPredict is not a numpy array\n        \n    Example:\n    \n        y_true = np.array([3, -0.5, 2, 7])\n        y_pred = np.array([2.5, 0.0, 2, 8])\n        mean_absolute_error(y_pred, y_true)\n        \n    \"\"\"\n    if not isinstance(y_true, np.ndarray):\n        raise AssertionError(\"{} must be of type numpy.ndarray\".format(y_true))\n    \n    if not isinstance(y_pred, np.ndarray):\n        raise AssertionError(\"{} must be of type numpy.ndarray\".format(y_pred))\n    \n    if not (y_pred.size == y_true.size):\n        raise AssertionError(\"The predicted array and the ground truth arrays must be of the same size\")\n    \n    return np.sum(np.absolute(y_pred - y_true))/y_pred.size",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_true = np.array([3, -0.5, 2, 7])\ny_pred = np.array([2.5, 0.0, 2, 8])\nmean_absolute_error(y_pred, y_true)(y_pred, y_true)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "0.5"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Mean Squared Error\n\nThe Mean Squared Error (or MSE) is much like the mean absolute error in that it provides a gross idea of the magnitude of error.\n\nTaking the square root of the mean squared error converts the units back to the original units of the output variable and can be meaningful for description and presentation. This is called the Root Mean Squared Error (or RMSE).\n\nIt is defined as:\n\n$$\\frac{\\sum_{i = 1}^n (y_i - x_i)^2}{n}$$"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def mean_squared_error(y_pred, y_true):\n    \"\"\"Calculates the Mean Square error between the two input numpy arrays.\n    \n    Args:\n        rgs:\n        y_pred (numpy ndarray): The true lables. Ground truth.\n        y_true (numpy ndarray): The predicted lables. Predictions.\n    \n    Raises:\n        Assertion Exception: If yTrue or yPredict is not a numpy array\n        \n    Example:\n    \n        y_true = np.array([3, -0.5, 2, 7])\n        y_pred = np.array([2.5, 0.0, 2, 8])\n        mean_squared_error(y_pred, y_true)\n        \n    \"\"\"\n    if not isinstance(y_true, np.ndarray):\n        raise AssertionError(\"{} must be of type numpy.ndarray\".format(y_true))\n    \n    if not isinstance(y_pred, np.ndarray):\n        raise AssertionError(\"{} must be of type numpy.ndarray\".format(y_pred))\n    \n    if not (y_pred.size == y_true.size):\n        raise AssertionError(\"The predicted array and the ground truth arrays must be of the same size\")\n    \n    return np.sum((y_pred - y_true)**2)/y_pred.size",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_true = np.array([3, -0.5, 2, 7])\ny_pred = np.array([2.5, 0.0, 2, 8])\nmean_squared_error(y_pred, y_true)",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "0.375"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}